name: Schema Rebuild

on:
  workflow_dispatch:
    inputs:
      database:
        description: 'Which database to rebuild'
        type: choice
        options:
          - forward
          - reverse
          - both
        default: both
      confirm:
        description: 'Type "REBUILD" to confirm (service will be unavailable during rebuild)'
        type: string
        required: true

env:
  CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
  CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - name: Validate confirmation
        run: |
          if [ "${{ github.event.inputs.confirm }}" != "REBUILD" ]; then
            echo "Error: You must type 'REBUILD' to confirm this destructive operation"
            exit 1
          fi
          echo "Confirmation validated. Proceeding with schema rebuild..."

  rebuild:
    needs: validate
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install DuckDB CLI
        run: |
          curl -LO https://github.com/duckdb/duckdb/releases/download/v1.1.3/duckdb_cli-linux-amd64.zip
          unzip duckdb_cli-linux-amd64.zip
          chmod +x duckdb
          sudo mv duckdb /usr/local/bin/

      - name: Install Python dependencies
        run: pip install duckdb

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"

      - name: Install npm dependencies
        run: npm ci

      - name: Get latest Overture release
        id: release
        run: |
          chmod +x scripts/check_release.sh
          ./scripts/check_release.sh

      - name: Download global divisions from Overture
        run: |
          chmod +x scripts/download_divisions.sh
          ./scripts/download_divisions.sh "${{ steps.release.outputs.overture_release }}"

      - name: Build divisions indexes
        run: |
          mkdir -p indexes
          python scripts/build_divisions_index.py
          python scripts/build_divisions_reverse_index.py

      # ==================== FORWARD GEOCODING ====================
      - name: Export forward geocoding SQL
        if: github.event.inputs.database == 'forward' || github.event.inputs.database == 'both'
        run: |
          python scripts/export_to_sql.py \
            indexes/divisions-global.db \
            exports/forward-full \
            --table divisions

      - name: Apply forward schema (DROP + CREATE)
        if: github.event.inputs.database == 'forward' || github.event.inputs.database == 'both'
        run: |
          echo "⚠️  Dropping and recreating forward geocoding tables..."
          npx wrangler d1 execute geocoder-divisions-global \
            --remote \
            --file=exports/forward-full/schema.sql

      - name: Apply forward data
        if: github.event.inputs.database == 'forward' || github.event.inputs.database == 'both'
        run: |
          for file in exports/forward-full/data-*.sql; do
            echo "Uploading $file..."
            npx wrangler d1 execute geocoder-divisions-global \
              --remote \
              --file="$file"
          done

      - name: Update forward metadata
        if: github.event.inputs.database == 'forward' || github.event.inputs.database == 'both'
        run: |
          npx wrangler d1 execute geocoder-divisions-global --remote --command \
            "INSERT OR REPLACE INTO metadata (key, value) VALUES ('overture_release', '${{ steps.release.outputs.overture_release }}')"

      # ==================== REVERSE GEOCODING ====================
      - name: Export reverse geocoding SQL
        if: github.event.inputs.database == 'reverse' || github.event.inputs.database == 'both'
        run: |
          python scripts/export_to_sql.py \
            indexes/divisions-reverse.db \
            exports/reverse-full \
            --table divisions_reverse

      - name: Apply reverse schema (DROP + CREATE)
        if: github.event.inputs.database == 'reverse' || github.event.inputs.database == 'both'
        run: |
          echo "⚠️  Dropping and recreating reverse geocoding tables..."
          npx wrangler d1 execute geocoder-divisions-reverse \
            --remote \
            --file=exports/reverse-full/schema.sql

      - name: Apply reverse data
        if: github.event.inputs.database == 'reverse' || github.event.inputs.database == 'both'
        run: |
          for file in exports/reverse-full/data-*.sql; do
            echo "Uploading $file..."
            npx wrangler d1 execute geocoder-divisions-reverse \
              --remote \
              --file="$file"
          done

      - name: Update reverse metadata
        if: github.event.inputs.database == 'reverse' || github.event.inputs.database == 'both'
        run: |
          npx wrangler d1 execute geocoder-divisions-reverse --remote --command \
            "INSERT OR REPLACE INTO metadata (key, value) VALUES ('overture_release', '${{ steps.release.outputs.overture_release }}')"

      # ==================== VERIFY ====================
      - name: Verify rebuild
        run: |
          echo "Verifying forward geocoding..."
          npx wrangler d1 execute geocoder-divisions-global --remote --command "SELECT * FROM metadata" --json || true
          npx wrangler d1 execute geocoder-divisions-global --remote --command "SELECT COUNT(*) as count FROM divisions" --json || true

          echo "Verifying reverse geocoding..."
          npx wrangler d1 execute geocoder-divisions-reverse --remote --command "SELECT * FROM metadata" --json || true
          npx wrangler d1 execute geocoder-divisions-reverse --remote --command "SELECT COUNT(*) as count FROM divisions_reverse" --json || true
